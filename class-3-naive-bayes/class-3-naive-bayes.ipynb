{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Programa de Pós-Graduação em Computação - INF/UFRGS**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Disciplina CMP263 - Aprendizagem de Máquina\n",
        "#### *Profa. Mariana Recamonde-Mendoza (mrmendoza@inf.ufrgs.br)*\n",
        "<br>\n",
        "\n",
        "---\n",
        "***Observação:*** *Este notebook é disponibilizado aos alunos como complemento às aulas  e aos slides preparados pela professora. Desta forma, os principais conceitos são apresentados no material teórico fornecido. O objetivo deste notebook é reforçar os conceitos e demonstrar questões práticas no uso de algoritmos e estratégias de avaliação em Aprendizado de Máquina.*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "##**Tópico: Naïve Bayes**\n",
        "\n",
        "\n",
        "**Objetivos do notebook:**\n",
        "-  Demonstrar o processo de treinamento e avaliação de modelos com o algoritmo Naïve Bayes e a técnica Holdout;\n",
        "- Explorar o modelo Naïve Bayes, em termos de parâmetros estimados e fronteira de decisão gerada."
      ],
      "metadata": {
        "id": "NS36dV7R-4Zn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnMQc3FH9DdN"
      },
      "outputs": [],
      "source": [
        "## Naive Bayes com dados de câncer de mama\n",
        "\n",
        "# 1. Importando bibliotecas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# 2. Carregando o dataset a partir do sklearn\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "print(\"Features:\", cancer.feature_names[:10], \"...\")\n",
        "print(\"Classes:\", cancer.target_names)\n",
        "\n",
        "# 3. Dividir em treino e teste, de forma estratificada\n",
        "# O uso do random_state visa garantir reprodutibilidade dos experimentos.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Treinar modelo Naive Bayes Gaussiano, com configuração padrão de hiperparâmetros\n",
        "# Na etapa de treinamento, o algoritmo estima todas as probabilidades envolvidas na tomada de decisão\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "Mnihsefb9jTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Número de instâncias por classe\n",
        "print(\"Número de instâncias por classe:\", nb.class_count_)\n",
        "\n",
        "# Probabilidade a priori das classes\n",
        "print(\"Probabilidades a priori:\", nb.class_prior_)\n",
        "\n",
        "# Médias das features por classe\n",
        "df_means = pd.DataFrame(nb.theta_, columns=cancer.feature_names, index=cancer.target_names)\n",
        "print(\"\\nMédias estimadas por classe:\")\n",
        "display(df_means)\n",
        "\n",
        "# Variâncias das features por classe\n",
        "df_vars = pd.DataFrame(nb.var_, columns=cancer.feature_names, index=cancer.target_names)\n",
        "print(\"\\nVariâncias estimadas por classe:\")\n",
        "display(df_vars)\n"
      ],
      "metadata": {
        "id": "TTocbYks9u3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Avaliar modelo\n",
        "y_pred = nb.predict(X_test)\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred, target_names=cancer.target_names))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=cancer.target_names, yticklabels=cancer.target_names, cmap='Blues')\n",
        "plt.xlabel(\"Predito\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.title(\"Matriz de Confusão\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Y0crKyX-9kuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Como referência, vamos avaliar o desempenho nos dados de treino, para averiguar o risco de overfitting\n",
        "y_pred_train = nb.predict(X_train)\n",
        "print(\"Acurácia:\", accuracy_score(y_train, y_pred_train))"
      ],
      "metadata": {
        "id": "ZISIUwiA-SgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Mostrar probabilidades em alguns exemplos do teste\n",
        "print(\"Exemplos de probabilidades preditas:\")\n",
        "for i in range(5):\n",
        "    probs = nb.predict_proba([X_test[i]])[0]\n",
        "    print(f\"Exemplo {i}: Probabilidades = {probs}, Classe real = {cancer.target_names[y_test[i]]}, Classe predita = {cancer.target_names[y_pred[i]]}\")\n"
      ],
      "metadata": {
        "id": "vLEEWgzT9n2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Plotar fronteira de decisão (usando só duas features para visualização)\n",
        "# Vamos escolher as duas primeiras features para simplificação\n",
        "X_vis = X_train[:, :2]\n",
        "X_test_vis = X_test[:, :2]\n",
        "\n",
        "nb_vis = GaussianNB()\n",
        "nb_vis.fit(X_vis, y_train)\n",
        "\n",
        "# Criar grid para plotar\n",
        "x_min, x_max = X_vis[:, 0].min() - 1, X_vis[:, 0].max() + 1\n",
        "y_min, y_max = X_vis[:, 1].min() - 1, X_vis[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
        "\n",
        "Z = nb_vis.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.contourf(xx, yy, Z, alpha=0.3, cmap=ListedColormap([\"#FFAAAA\", \"#AAFFAA\"]))\n",
        "plt.scatter(X_vis[:, 0], X_vis[:, 1], c=y_train, edgecolor='k', cmap=ListedColormap([\"#FF0000\", \"#00FF00\"]), s=30)\n",
        "plt.xlabel(cancer.feature_names[0])\n",
        "plt.ylabel(cancer.feature_names[1])\n",
        "plt.title(\"Fronteira de decisão do Naive Bayes (duas features)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9x01G1rT-eBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Reduzindo para 2 componentes\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Treinar NB no espaço reduzido\n",
        "nb_pca = GaussianNB()\n",
        "nb_pca.fit(X_train_pca, y_train)\n",
        "\n",
        "# Grid para plotar\n",
        "x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
        "y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
        "\n",
        "Z = nb_pca.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.contourf(xx, yy, Z, alpha=0.3, cmap=ListedColormap([\"#FFAAAA\", \"#AAFFAA\"]))\n",
        "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, edgecolor='k', cmap=ListedColormap([\"#FF0000\", \"#00FF00\"]), s=30)\n",
        "plt.xlabel(\"PCA 1\")\n",
        "plt.ylabel(\"PCA 2\")\n",
        "plt.title(\"Fronteira de decisão (NB em espaço PCA das 30 features)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6DctZoFq-s-r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}